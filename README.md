![Illustration](.github/illustration.png)

## HopkinsGPT

Petit test d'utilisation d'ollama pour discuter avec mon chien ! Vous pouvez voir [ce projet](https://hopkins.elias.my) en ligne, mais il n'utilise que AI Endpoints (je n'ai pas de serveur assez puissant pour faire tourner des mod√®les üòÖ). N√©anmoins, vous pouvez cloner ce repo, et lancer Ollama avec `ollama serve` puis le projet avec `npm run build && npm run start` pour avoir vos mod√®les en local !

## Installation

Suivre les instructions sur le site de [Ollama](https://ollama.com/) pour installer Ollama.
Installez ensuite les diff√©rents mod√®les avec `ollama pull <model>`.

Cr√©ez un fichier `.env` √† la racine du projet contenant l'URL de l'API de votre instance Ollama :

```bash
OLLAMA_API_URL=http://localhost:11434/api/
AI_ENDPOINTS_TOKEN=your_token
```

Pour obtenir votre token de AI Endpoints, rendez-vous sur le site de [OVHcloud](https://endpoints.ai.cloud.ovh.net/).
